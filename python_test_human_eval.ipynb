{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ffd3a00",
   "metadata": {},
   "source": [
    "# initial tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce0da9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/watsonjo/.pyenv/versions/3.7.16/lib/python3.7/site-packages (0.21.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2726ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY=os.getenv(\"API_KEY\")\n",
    "# MODEL=\"gpt-3.5-turbo-0125\"\n",
    "MODEL=\"gpt-4-0125-preview\"\n",
    "additional_context_enabled = True\n",
    "previous_attempts_enabled = True\n",
    "\n",
    "def listModels():\n",
    "    url = \"https://api.openai.com/v1/models\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + API_KEY,\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    print(response.json())\n",
    "def gpt(code, additional_context = '', error = '', ae = '', previous_code = ''):\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + API_KEY,\n",
    "    }\n",
    "    context = \"You are a tool used to automatically generate source code for unit tests. Source code for a function that is to be tested will be provided and you should generate an appropriate unit test that can be ran to ensure the code is correct. Code input will be in Python and you should respond with a Python code block containing the unit test as output. Do not use any testing frameworks. Do not start output with \\\"```python\\\". Don't use Parametrize. For assertions dealing with numbers, allow a tolerance of 1e^-5. Ensure the file can be run directly using a check for __name__==\\\"main\\\". Add assertion messages for failures. Do not include the original function in the response. Use the global keyword with all function names and required imports that need to be called in the test as the first lines of the test function.\"\n",
    "    if additional_context and additional_context_enabled:\n",
    "        context += \" Some additional context about the method under test is \\\"\"+additional_context+\"\\\".\"\n",
    "    if previous_code and previous_attempts_enabled:\n",
    "        context += \" Previously, you generated \\\"\"+previous_code+\"\\\".\"\n",
    "    if error and previous_attempts_enabled:\n",
    "        context += \" This was executed and the following was the result \\\"\"+error+\"\\\". Provide a new solution in the same format, which fixes the problems.\"\n",
    "    if ae and previous_attempts_enabled:\n",
    "        context += \" This was executed and there was a failed assertion \\\"\"+ae+\"\\\". Try fix the test for the failed assertion, leaving all the passing assertions unchanged and return the updated result.\"\n",
    "#     print(context)\n",
    "#     print(code)\n",
    "    data = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "          {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": context\n",
    "          },\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "              import math\n",
    "              \n",
    "              def add(a, b):\n",
    "                return a + b\"\n",
    "              \"\"\"\n",
    "          },\n",
    "          {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"def test_add():\\n    global test_add, math\\n    assert add(3, 5) == 8, \\\"Test case 1 failed\\\"\\n    assert add(-3, -5) == -8, \\\"Test case 2 failed\\\"\\n    assert add(3, -5) == -2, \\\"Test case 3 failed\\\"\\nif __name__ == \\\"__main__\\\":\\n    test_add()\"\n",
    "          },\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": code\n",
    "          },\n",
    "        ],\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 1.0,\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    output = response.json()['choices'][0]['message']['content']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "883fb710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanEval/29, passes(attempt 1)\n",
      "HumanEval/30, passes(attempt 1)\n",
      "HumanEval/31, passes(attempt 1)\n",
      "HumanEval/32 - attempt 1, failed assertion\n",
      "HumanEval/32 - attempt 2, failed assertion\n",
      "HumanEval/32 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/33 - attempt 1, failed assertion\n",
      "HumanEval/33 - attempt 2, failed assertion\n",
      "HumanEval/33 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/34, passes(attempt 1)\n",
      "HumanEval/35, passes(attempt 1)\n",
      "HumanEval/36, passes(attempt 1)\n",
      "HumanEval/37, passes(attempt 1)\n",
      "HumanEval/38 - attempt 1, failed assertion\n",
      "HumanEval/38 - attempt 2, failed assertion\n",
      "HumanEval/38 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/39, passes(attempt 1)\n",
      "HumanEval/40, passes(attempt 1)\n",
      "HumanEval/41, passes(attempt 1)\n",
      "HumanEval/42, passes(attempt 1)\n",
      "HumanEval/43, passes(attempt 1)\n",
      "HumanEval/44 - attempt 1, failed assertion\n",
      "HumanEval/44 - attempt 2, failed assertion\n",
      "HumanEval/44, passes(attempt 3)\n",
      "HumanEval/45 - attempt 1, failed to run\n",
      "HumanEval/45, passes(attempt 2)\n",
      "HumanEval/46, passes(attempt 1)\n",
      "HumanEval/47 - attempt 1, failed assertion\n",
      "HumanEval/47 - attempt 2, failed assertion\n",
      "HumanEval/47 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/48, passes(attempt 1)\n",
      "HumanEval/49, passes(attempt 1)\n",
      "HumanEval/50 - attempt 1, failed assertion\n",
      "HumanEval/50 - attempt 2, failed assertion\n",
      "HumanEval/50 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/51, passes(attempt 1)\n",
      "HumanEval/52, passes(attempt 1)\n",
      "HumanEval/53, passes(attempt 1)\n",
      "HumanEval/54, passes(attempt 1)\n",
      "HumanEval/55, passes(attempt 1)\n",
      "HumanEval/56, passes(attempt 1)\n",
      "HumanEval/57, passes(attempt 1)\n",
      "HumanEval/58, passes(attempt 1)\n",
      "HumanEval/59, passes(attempt 1)\n",
      "HumanEval/60, passes(attempt 1)\n",
      "HumanEval/61, passes(attempt 1)\n",
      "HumanEval/62, passes(attempt 1)\n",
      "HumanEval/63, passes(attempt 1)\n",
      "HumanEval/64 - attempt 1, failed assertion\n",
      "HumanEval/64 - attempt 2, failed assertion\n",
      "HumanEval/64 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/65 - attempt 1, failed assertion\n",
      "HumanEval/65, passes(attempt 2)\n",
      "HumanEval/66, passes(attempt 1)\n",
      "HumanEval/67, passes(attempt 1)\n",
      "HumanEval/68, passes(attempt 1)\n",
      "HumanEval/69, passes(attempt 1)\n",
      "HumanEval/70, passes(attempt 1)\n",
      "HumanEval/71, passes(attempt 1)\n",
      "HumanEval/72, passes(attempt 1)\n",
      "HumanEval/73, passes(attempt 1)\n",
      "HumanEval/74, passes(attempt 1)\n",
      "HumanEval/75 - attempt 1, failed assertion\n",
      "HumanEval/75, passes(attempt 2)\n",
      "HumanEval/76, passes(attempt 1)\n",
      "HumanEval/77, passes(attempt 1)\n",
      "HumanEval/78, passes(attempt 1)\n",
      "HumanEval/79, passes(attempt 1)\n",
      "HumanEval/80, passes(attempt 1)\n",
      "HumanEval/81 - attempt 1, failed assertion\n",
      "HumanEval/81 - attempt 2, failed assertion\n",
      "HumanEval/81 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/82, passes(attempt 1)\n",
      "HumanEval/83, passes(attempt 1)\n",
      "HumanEval/84 - attempt 1, failed assertion\n",
      "HumanEval/84, passes(attempt 2)\n",
      "HumanEval/85 - attempt 1, failed assertion\n",
      "HumanEval/85 - attempt 2, failed assertion\n",
      "HumanEval/85 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/86, passes(attempt 1)\n",
      "HumanEval/87 - attempt 1, failed assertion\n",
      "HumanEval/87, passes(attempt 2)\n",
      "HumanEval/88 - attempt 1, failed assertion\n",
      "HumanEval/88 - attempt 2, failed assertion\n",
      "HumanEval/88 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/89, passes(attempt 1)\n",
      "HumanEval/90, passes(attempt 1)\n",
      "HumanEval/91, passes(attempt 1)\n",
      "HumanEval/92 - attempt 1, failed assertion\n",
      "HumanEval/92, passes(attempt 2)\n",
      "HumanEval/93 - attempt 1, failed assertion\n",
      "HumanEval/93 - attempt 2, failed assertion\n",
      "HumanEval/93 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/94, passes(attempt 1)\n",
      "HumanEval/95, passes(attempt 1)\n",
      "HumanEval/96, passes(attempt 1)\n",
      "HumanEval/97 - attempt 1, failed assertion\n",
      "HumanEval/97, passes(attempt 2)\n",
      "HumanEval/98, passes(attempt 1)\n",
      "HumanEval/99 - attempt 1, failed to run\n",
      "HumanEval/99 - attempt 2, failed to run\n",
      "HumanEval/99 - attempt 3, failed to run\n",
      "could not convert string to float: \n",
      "HumanEval/100, passes(attempt 1)\n",
      "HumanEval/101, passes(attempt 1)\n",
      "HumanEval/102 - attempt 1, failed assertion\n",
      "HumanEval/102 - attempt 2, failed assertion\n",
      "HumanEval/102 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/103, passes(attempt 1)\n",
      "HumanEval/104 - attempt 1, failed assertion\n",
      "HumanEval/104 - attempt 2, failed assertion\n",
      "HumanEval/104 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/105, passes(attempt 1)\n",
      "HumanEval/106 - attempt 1, failed assertion\n",
      "HumanEval/106 - attempt 2, failed assertion\n",
      "HumanEval/106 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/107 - attempt 1, failed assertion\n",
      "HumanEval/107 - attempt 2, failed assertion\n",
      "HumanEval/107 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/108 - attempt 1, failed assertion\n",
      "HumanEval/108 - attempt 2, failed assertion\n",
      "HumanEval/108 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/109, passes(attempt 1)\n",
      "HumanEval/110, passes(attempt 1)\n",
      "HumanEval/111, passes(attempt 1)\n",
      "HumanEval/112, passes(attempt 1)\n",
      "HumanEval/113, passes(attempt 1)\n",
      "HumanEval/114 - attempt 1, failed assertion\n",
      "HumanEval/114 - attempt 2, failed assertion\n",
      "HumanEval/114 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/115, passes(attempt 1)\n",
      "HumanEval/116 - attempt 1, failed assertion\n",
      "HumanEval/116 - attempt 2, failed assertion\n",
      "HumanEval/116 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/117, passes(attempt 1)\n",
      "HumanEval/118 - attempt 1, failed assertion\n",
      "HumanEval/118 - attempt 2, failed assertion\n",
      "HumanEval/118, passes(attempt 3)\n",
      "HumanEval/119 - attempt 1, failed assertion\n",
      "HumanEval/119, passes(attempt 2)\n",
      "HumanEval/120, passes(attempt 1)\n",
      "HumanEval/121 - attempt 1, failed assertion\n",
      "HumanEval/121, passes(attempt 2)\n",
      "HumanEval/122, passes(attempt 1)\n",
      "HumanEval/123 - attempt 1, failed assertion\n",
      "HumanEval/123 - attempt 2, failed assertion\n",
      "HumanEval/123 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/124 - attempt 1, failed assertion\n",
      "HumanEval/124 - attempt 2, failed assertion\n",
      "HumanEval/124 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/125 - attempt 1, failed assertion\n",
      "HumanEval/125 - attempt 2, failed assertion\n",
      "HumanEval/125 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/126, passes(attempt 1)\n",
      "HumanEval/127 - attempt 1, failed assertion\n",
      "HumanEval/127, passes(attempt 2)\n",
      "HumanEval/128, passes(attempt 1)\n",
      "HumanEval/129 - attempt 1, failed assertion\n",
      "HumanEval/129 - attempt 2, failed assertion\n",
      "HumanEval/129 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/130, passes(attempt 1)\n",
      "HumanEval/131, passes(attempt 1)\n",
      "HumanEval/132, passes(attempt 1)\n",
      "HumanEval/133, passes(attempt 1)\n",
      "HumanEval/134, passes(attempt 1)\n",
      "HumanEval/135 - attempt 1, failed assertion\n",
      "HumanEval/135, passes(attempt 2)\n",
      "HumanEval/136, passes(attempt 1)\n",
      "HumanEval/137, passes(attempt 1)\n",
      "HumanEval/138, passes(attempt 1)\n",
      "HumanEval/139, passes(attempt 1)\n",
      "HumanEval/140 - attempt 1, failed assertion\n",
      "HumanEval/140 - attempt 2, failed assertion\n",
      "HumanEval/140 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/141 - attempt 1, failed assertion\n",
      "HumanEval/141, passes(attempt 2)\n",
      "HumanEval/142 - attempt 1, failed assertion\n",
      "HumanEval/142 - attempt 2, failed assertion\n",
      "HumanEval/142 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/143 - attempt 1, failed assertion\n",
      "HumanEval/143 - attempt 2, failed assertion\n",
      "HumanEval/143 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/144, passes(attempt 1)\n",
      "HumanEval/145 - attempt 1, failed assertion\n",
      "HumanEval/145 - attempt 2, failed assertion\n",
      "HumanEval/145 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/146, passes(attempt 1)\n",
      "HumanEval/147 - attempt 1, failed assertion\n",
      "HumanEval/147 - attempt 2, failed assertion\n",
      "HumanEval/147 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/148 - attempt 1, failed assertion\n",
      "HumanEval/148, passes(attempt 2)\n",
      "HumanEval/149 - attempt 1, failed assertion\n",
      "HumanEval/149 - attempt 2, failed assertion\n",
      "HumanEval/149 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/150, passes(attempt 1)\n",
      "HumanEval/151, passes(attempt 1)\n",
      "HumanEval/152, passes(attempt 1)\n",
      "HumanEval/153 - attempt 1, failed assertion\n",
      "HumanEval/153 - attempt 2, failed assertion\n",
      "HumanEval/153 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/154, passes(attempt 1)\n",
      "HumanEval/155, passes(attempt 1)\n",
      "HumanEval/156, passes(attempt 1)\n",
      "HumanEval/157 - attempt 1, failed assertion\n",
      "HumanEval/157, passes(attempt 2)\n",
      "HumanEval/158, passes(attempt 1)\n",
      "HumanEval/159, passes(attempt 1)\n",
      "HumanEval/160 - attempt 1, failed assertion\n",
      "HumanEval/160 - attempt 2, failed assertion\n",
      "HumanEval/160 - attempt 3, failed assertion\n",
      "\n",
      "HumanEval/161, passes(attempt 1)\n",
      "HumanEval/162, passes(attempt 1)\n",
      "HumanEval/163, passes(attempt 1)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import traceback\n",
    "import re\n",
    "import time    \n",
    "SAMPLES_TO_RUN = 164\n",
    "ADDITIONAL_ATTEMPTS = 2\n",
    "# TEST_NAME = \"gpt-3.5-turbo-0125-2attempt-context\"\n",
    "TEST_NAME = \"gpt-4-0125-preview-2attempt-context\"\n",
    "count = 0\n",
    "def exec_code(instance):\n",
    "#     eval_program, prompt, check_program, out, attempts=0\n",
    "    error = ''\n",
    "    ae = ''\n",
    "    instance2j = json.dumps(instance)\n",
    "    instance2= json.loads(instance2j)\n",
    "    check_program = (\n",
    "                instance2['prompt'] + \n",
    "                instance2['canonical_solution'] + \"\\n\" + \n",
    "                instance2['test'] + \"\\n\"\n",
    "#                 \"def test_below_zero():\\n    assert not below_zero([1, 2, 3]), \\\"Test case 1 failed: should not fall below zero\\\"\\n    assert below_zero([1, 2, -4, 5]), \\\"Test case 2 failed: should fall below zero\\\"\\n    assert not below_zero([]), \\\"Test case 3 failed: empty list should not fall below zero\\\"\\n    assert below_zero([-1, 2, -3, 4]), \\\"Test case 4 failed: should fall below zero on first operation\\\"\\n    assert not below_zero([100, -50, -25]), \\\"Test case 5 failed: should not fall below zero\\\"\\n    assert below_zero([-1, -2, -3]), \\\"Test case 6 failed: should fall below zero on the first operation\\\"\\n\\nif __name__ == \\\"__main__\\\":\\n    test_below_zero()\"\n",
    "#                 \"def test_below_zero():\\n    global below_zero\\n    assert not below_zero([1, 2, 3]), \\\"Test case 1 failed: should not fall below zero\\\"\\n    assert below_zero([1, 2, -4, 5]), \\\"Test case 2 failed: should fall below zero\\\"\\n    assert not below_zero([]), \\\"Test case 3 failed: empty list should not fall below zero\\\"\\n    assert below_zero([-1, 2, -3, 4]), \\\"Test case 4 failed: should fall below zero on first operation\\\"\\n    assert not below_zero([100, -50, -25]), \\\"Test case 5 failed: should not fall below zero\\\"\\n    assert below_zero([-1, -2, -3]), \\\"Test case 6 failed: should fall below zero on the first operation\\\"\\n\\nif __name__ == \\\"__main__\\\":\\n    test_below_zero()\"\n",
    "\n",
    "#                 \"if __name__ == \\\"__main__\\\":\\n    below_zero([-1, 1])\"\n",
    "            )\n",
    "    \n",
    "    try:\n",
    "        compiled_code = compile(check_program, \"<string>\", \"exec\")\n",
    "        exec(compiled_code)\n",
    "        instance[\"runs\"] = True\n",
    "        instance[\"passes\"] = True\n",
    "        print(f\"{instance['task_id']}, passes(attempt {instance['attempts_made']})\")\n",
    "        return instance\n",
    "    except AssertionError as err:\n",
    "        tb = traceback.format_exc()\n",
    "        instance['runs'] = True\n",
    "        instance['passes'] = False\n",
    "        print(f\"{instance['task_id']} - attempt {instance['attempts_made']}, failed assertion\")\n",
    "        try:\n",
    "            ae = re.match(r'.*(AssertionError: .*)', tb.replace(\"\\n\",\"\")).group(1)\n",
    "        except Exception as f:\n",
    "            ae = err\n",
    "        instance['error'] = ae\n",
    "    except Exception as e:\n",
    "        instance['runs'] = False\n",
    "        instance['passes'] = False\n",
    "        print(f\"{instance['task_id']} - attempt {instance['attempts_made']}, failed to run\")\n",
    "#         print(\"\\'''\\n\" + check_program + \"\\n'''\")\n",
    "#         print(str(e))\n",
    "        error = str(e)\n",
    "        instance['error'] = error\n",
    "    if instance['attempts_made'] > ADDITIONAL_ATTEMPTS:\n",
    "        if not instance['passes']:\n",
    "            print(error)\n",
    "        return instance\n",
    "    next_instance = {\n",
    "        'task_id': instance['task_id'],\n",
    "        'prompt': instance['prompt'],\n",
    "        'canonical_solution': instance['canonical_solution'],\n",
    "        'attempts_made': instance['attempts_made']+1,\n",
    "        'previous_attempt': instance\n",
    "    }\n",
    "#     next_attempt = \"      def has_close_elemnts(numbers, threshold):\\n    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n    return False\\ndef test_has_close_elements():\\n    assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False, \\\"Test case 1 failed\\\"\\n    assert has_close_elements([1.0, 2.8, 3.0], 0.21) == True, \\\"Test case 2 failed\\\"\\n    assert has_close_elements([0.1, 0.2, 0.3], 0.11) == True, \\\"Test case 3 failed\\\"\\n    assert has_close_elements([10, 20, 30], 10.1) == True, \\\"Test case 4 failed\\\"\\n    assert has_close_elements([100, 200, 300], 100.1) == True, \\\"Test case 5 failed\\\"\\n    assert has_close_elements([], 0.5) == False, \\\"Test case 6 failed\\\"\\n    assert has_close_elements([1.000001, 1.000002], 0.0000001) == False, \\\"Test case 7 failed\\\"\\n    assert has_close_elements([1.000001, 1.000002], 0.000001) == True, \\\"Test case 8 failed\\\"\\nif __name__ == \\\"__main__\\\":\\n    test_has_close_elements()\"\n",
    "#     if instance['attempts_made'] > 1:\n",
    "#         next_attempt = \"def has_close_elements(numbers, threshold):\\n    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n    return False\\ndef test_has_close_elements():\\n    assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False, \\\"Test case 1 failed\\\"\\n    assert has_close_elements([1.0, 2.8, 3.0], 0.21) == True, \\\"Test case 2 failed\\\"\\n    assert has_close_elements([0.1, 0.2, 0.3], 0.11) == True, \\\"Test case 3 failed\\\"\\n    assert has_close_elements([10, 20, 30], 10.1) == True, \\\"Test case 4 failed\\\"\\n    assert has_close_elements([100, 200, 300], 100.1) == True, \\\"Test case 5 failed\\\"\\n    assert has_close_elements([], 0.5) == False, \\\"Test case 6 failed\\\"\\n    assert has_close_elements([1.000001, 1.000002], 0.0000001) == False, \\\"Test case 7 failed\\\"\\nif __name__ == \\\"__main__\\\":\\n    test_has_close_elements()\"\n",
    "    next_attempt = gpt(instance['canonical_solution'], instance[\"prompt\"], error, ae, instance[\"test\"])\n",
    "    next_instance['test'] = next_attempt\n",
    "    return exec_code(next_instance)\n",
    "\n",
    "with open('HumanEval.jsonl') as file:\n",
    "    timestamp = time.time()\n",
    "    filename = f\"results/{TEST_NAME}_{timestamp}.jsonl\"\n",
    "    open(filename, \"x\")\n",
    "    for line in file:\n",
    "        count += 1\n",
    "        if count < 30:\n",
    "            continue\n",
    "        instance = json.loads(line)\n",
    "        instance['attempts_made'] = 1\n",
    "        split_prompt = re.match(r\"^(.*def .*?:\\n)(.*)\", instance['prompt'], re.M|re.DOTALL)\n",
    "        instance['canonical_solution'] = split_prompt.group(1) + instance['canonical_solution']\n",
    "        instance['prompt'] = split_prompt.group(2).replace(\"    \",\"\")\n",
    "        instance['test'] = gpt(instance['canonical_solution'], instance[\"prompt\"])\n",
    "#         instance['test'] = \"def has_close_elements(numbers, threshold):\\n    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n    return False\\ndef test_has_close_elements():\\n    assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False, \\\"Test case 1 failed\\\"\\n    assert has_close_elements([1.0, 2.8, 3.0], 0.21) == True, \\\"Test case 2 failed\\\"\\n    assert has_close_elements([0.1, 0.2, 0.3], 0.11) == True, \\\"Test case 3 failed\\\"\\n    assert has_close_elements([10, 20, 30], 10.1) == True, \\\"Test case 4 failed\\\"\\n    assert has_close_elements([100, 200, 300], 100.1) == True, \\\"Test case 5 failed\\\"\\n    assert has_close_elements([], 0.5) == False, \\\"Test case 6 failed\\\"\\n    assert has_close_elements([1.000001, 1.000002], 0.0000001) == False, \\\"Test case 7 failed\\\"\\n    assert has_close_elements([1.000001, 1.000002], 0.000001) == True, \\\"Test case 8 failed\\\"\\nif __name__ == \\\"__main__\\\":\\n    test_has_close_elements()\"\n",
    "        out = exec_code(instance)\n",
    "        \n",
    "        with open(filename, 'a') as file:\n",
    "            json.dump(out, file)\n",
    "            file.write('\\n')\n",
    "        if count > SAMPLES_TO_RUN-1:\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d563a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
